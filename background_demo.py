# -*- coding: utf-8 -*-
"""Background Demo

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-DTV7vTajcKjJ63CNsnxG4MV7Ps02_3T

# Setup
"""




import ultralytics
import yaml
ultralytics.checks()
import cv2
import numpy as np
from ultralytics import YOLO
import os


# Set global environment variables for files in sample_data
SAMPLE_BACKGROUND_1 = os.path.join('sample_data', 'sample_background1.mp4')
SAMPLE_BACKGROUND_2 = os.path.join('sample_data', 'sample_background2.mp4')
CONFIG_FILE = 'config.yaml'
DATA_DIRECTORY = f'data'

# Load the segmentation model
model = YOLO("yolov8n-seg.pt")


with open(CONFIG_FILE, 'r') as file:
  yaml_config = yaml.safe_load(file)


# DEBUGGING GETTING VARIABLE FROM FILES - COMMENT AFTER USE
print(yaml_config["T1_FPS"])


"""SELECT WHAT VIDEO TO USE FOR BACKGROUND EXTRACTION HERE""" 
cap = cv2.VideoCapture(SAMPLE_BACKGROUND_1) # THAY CAM VÀO ĐÂY 

# Check if the video is opened successfully
if not cap.isOpened():
    print("Error opening video stream or file")

# Initialize frame counter
frame_counter = 0

# Assume video has 30 fps (idk how to get video fps)
fps = cap.get(cv2.CAP_PROP_FPS)
frame_number = fps / yaml_config["T1_FPS"]
# print frame_number
print("Video fps: ", fps)
print("Amount of frames needed to take 1 frame: ", frame_number)

while cap.isOpened():
    success, frame = cap.read()
    if success:
        # Increment frame counter
        frame_counter += 1

        # Process every 60th frame
        if frame_counter % frame_number == 0:
            # Run segmentation model through the frame
            results = model(frame)

            # Get segmentation mask
            if results and results[0].masks:
                segmentation_mask = results[0].masks.data[0].cpu().numpy()

                # Create bg_mask with the same size as the frame
                bg_mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)

                # Resize segmentation_mask to match frame's shape
                resized_segmentation_mask = cv2.resize(segmentation_mask.astype(np.uint8), (frame.shape[1], frame.shape[0]))

                # Create new mask
                new_mask = np.logical_or(bg_mask, np.logical_not(resized_segmentation_mask))
                new_mask = new_mask.astype(np.uint8)

                # Calculate difference
                diff_ratio = np.sum(np.abs(new_mask - bg_mask)) / (frame.shape[0] * frame.shape[1])

                # Save frame as an image if the difference ratio is greater than 0.01
                if diff_ratio > yaml_config["T2_BACKGROUND_REGION"]:
                    cv2.imwrite(os.path.join('data', f"frame_{cap.get(cv2.CAP_PROP_POS_FRAMES)}.jpg"), frame)
    else:
        break

# Save the final mask created as a file
cv2.imwrite("final_mask.jpg", new_mask)
cap.release()

# count number of images in data

import os

image_count = len([name for name in os.listdir('/content/data') if os.path.isfile(os.path.join('/content/data', name))])
print(f"Number of images in 'data' folder: {image_count}")

"""# Processing"""

# prompt: print shape  of the first image in data

import cv2
import os

image_files = [f for f in os.listdir('/content/data') if f.endswith('.jpg')]

if image_files:
  first_image_path = os.path.join('/content/data', image_files[0])
  img = cv2.imread(first_image_path)
  if img is not None:
    print(img.shape)
  else:
    print("Could not read the image.")
else:
  print("No image files found in the data directory.")

# plot all images in data
# for demonstration purposes

import matplotlib.pyplot as plt
import os

def plot_images_in_directory(directory):
  """Plots all images in a given directory."""
  image_files = [f for f in os.listdir(directory) if f.endswith('.jpg')]
  for image_file in image_files:
    image_path = os.path.join(directory, image_file)
    try:
      img = plt.imread(image_path)
      plt.imshow(img)
      plt.title(image_file)
      plt.show()
    except Exception as e:
      print(f"Error loading or displaying image {image_file}: {e}")

plot_images_in_directory('/content/data')

# cv2 read images in data

import cv2
import os

def read_images_in_directory(directory):
  """Reads all images in a given directory using OpenCV."""
  image_files = [f for f in os.listdir(directory) if f.endswith('.jpg')]
  images = []
  for i in range(min(20,len(image_files))):
    image_path = os.path.join(directory, image_files[i])
    img = cv2.imread(image_path)
    if img is not None:
      images.append(img)
    else:
      print(f"Could not read image: {image_path}")
  return images

# Example usage:
images = read_images_in_directory('/content/data')
print(f"Read {len(images)} images from the directory.")

# Commented out IPython magic to ensure Python compatibility.
# %%time
# import matplotlib.pyplot as plt
# import numpy as np
# fa_background = np.median(images, axis=0).astype(np.uint8)
# cv2.imwrite('/content/background/background_median.png', fa_background)
# 
# plt.imshow(cv2.cvtColor(fa_background, cv2.COLOR_BGR2RGB))
# plt.show()

# prompt: print video length of each video in content

import cv2

def get_video_length(video_path):
  """Calculates and returns the length of a video in seconds."""
  cap = cv2.VideoCapture(video_path)
  if not cap.isOpened():
    return 0

  fps = cap.get(cv2.CAP_PROP_FPS)
  frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
  video_length = frame_count / fps if fps else 0

  cap.release()
  return video_length

# Loop through all files in the content directory
for filename in os.listdir('/content'):
  if filename.endswith(('.mp4', '.avi', '.mov')):  # Add other video extensions if needed
    video_path = os.path.join('/content', filename)
    video_length = get_video_length(video_path)
    print(f"Video: {filename}, Length: {video_length:.2f} seconds")
    

